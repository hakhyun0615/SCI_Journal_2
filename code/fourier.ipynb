{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import butter, filtfilt, freqz\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"../data/preprocessed/sales.csv\")\n",
    "sell_prices = pd.read_csv(\"../data/preprocessed/sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, freqz\n",
    "\n",
    "def estimate_periods_with_fourier(sale, start_col, save_plot=False):\n",
    "    # start_col 이후의 데이터만 선택\n",
    "    cols = [col for col in sale.index if col.startswith('d_') and int(col.split('_')[1]) >= int(start_col.split('_')[1])]\n",
    "    sale_values = sale[cols].values.astype(float)\n",
    "\n",
    "    # High-pass 필터 파라미터 계산 및 필터 적용\n",
    "    cutoff, order = 0.01, 10\n",
    "    nyquist = 0.5\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    filtered_sale_values = filtfilt(b, a, sale_values)  # 직접 필터 적용\n",
    "\n",
    "    # 필터링된 신호의 FFT\n",
    "    fft = np.fft.fft(filtered_sale_values)\n",
    "    frequencies = np.fft.fftfreq(len(filtered_sale_values), d=1)\n",
    "    magnitudes = np.abs(fft)\n",
    "\n",
    "    # 양의 주파수만 선택하고 진폭순 정렬\n",
    "    positive_mask = frequencies > 0\n",
    "    frequencies_pos = frequencies[positive_mask]  \n",
    "    magnitudes_pos = magnitudes[positive_mask]\n",
    "    sorted_indices = np.argsort(magnitudes_pos)[::-1]\n",
    "    \n",
    "    # 주파수 정렬\n",
    "    sorted_frequencies = frequencies_pos[sorted_indices]\n",
    "    sorted_magnitudes = magnitudes_pos[sorted_indices]\n",
    "\n",
    "    # 주기 계산\n",
    "    raw_periods = [1/f for f in sorted_frequencies if 1/f < len(sale_values)//2]\n",
    "    \n",
    "    # 유사한 주기 병합\n",
    "    merged_periods = []\n",
    "    \n",
    "    for period in raw_periods:\n",
    "        # 유사한 주기가 이미 있는지 확인\n",
    "        if not any(abs(period - p) <= max(1, p * 0.05) for p in merged_periods):\n",
    "            merged_periods.append(period)\n",
    "\n",
    "    # 주기별 누적 SNR 계산\n",
    "    snr_progression = []\n",
    "    reconstructed_values_list = []\n",
    "    \n",
    "    for i in range(1, len(merged_periods) + 1):\n",
    "        # i개의 주기만 사용하여 신호 복원\n",
    "        current_periods = merged_periods[:i]\n",
    "        reconstruct_fft = np.zeros_like(fft, dtype=complex)\n",
    "        \n",
    "        for period in current_periods:\n",
    "            freq = 1/period\n",
    "            freq_idx = np.argmin(np.abs(frequencies - freq))\n",
    "            \n",
    "            # 원본 진폭과 위상 보존\n",
    "            reconstruct_fft[freq_idx] = fft[freq_idx]\n",
    "            reconstruct_fft[-freq_idx] = fft[-freq_idx]\n",
    "        \n",
    "        # 복원 신호 생성\n",
    "        reconstructed_values = np.fft.ifft(reconstruct_fft).real\n",
    "        reconstructed_values_list.append(reconstructed_values)\n",
    "        \n",
    "        # SNR 계산\n",
    "        original_energy = np.sum(np.abs(filtered_sale_values) ** 2)\n",
    "        error_energy = np.sum(np.abs(filtered_sale_values - reconstructed_values) ** 2)\n",
    "        current_snr = 10 * np.log10(original_energy / error_energy)\n",
    "        snr_progression.append(current_snr)\n",
    "\n",
    "    if save_plot:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        \n",
    "        # SNR 진행도 플롯\n",
    "        plt.subplot(211)\n",
    "        plt.plot(range(1, len(snr_progression) + 1), snr_progression)\n",
    "        plt.xlabel('Number of Periods Used')\n",
    "        plt.ylabel('SNR (dB)')\n",
    "        plt.title(f'SNR Progression: {sale[\"state_id\"]}, {sale[\"item_id\"]}')\n",
    "        \n",
    "        # 원본 신호와 복원 신호 비교 플롯\n",
    "        plt.subplot(212)\n",
    "        plt.plot(filtered_sale_values, label='Original Signal', alpha=0.7)\n",
    "        plt.plot(reconstructed_values_list[-1], label='Reconstructed Signal', alpha=0.7)\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Signal Reconstruction Comparison')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../data/fourier/snr_progression/{sale['state_id']}_{sale['item_id']}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    return merged_periods, snr_progression\n",
    "\n",
    "\n",
    "def analyze_period_with_fourier(sales, first_sales_column_dict, save_result=False, save_plot=False):\n",
    "    # Fundamental Period, Period Strength\n",
    "    fourier_results = {}\n",
    "\n",
    "    for idx in sales.index:\n",
    "        sale = sales.iloc[idx]\n",
    "        key = (sale['state_id'], sale['item_id'])\n",
    "\n",
    "        # 시작 컬럼 가져오기\n",
    "        start_col = first_sales_column_dict.get(key)\n",
    "\n",
    "        # Fourier 분석 수행\n",
    "        periods, snr_progression = estimate_periods_with_fourier(sale, start_col, save_plot=save_plot)\n",
    "\n",
    "        # 결과 저장\n",
    "        fourier_results[key] = {\n",
    "            'periods': periods,\n",
    "            'snr_progression': snr_progression,\n",
    "        }\n",
    "\n",
    "    # 결과 저장 (Pickle 파일)\n",
    "    if save_result:\n",
    "        with open('../data/fourier/results.pkl', 'wb') as f:\n",
    "            pickle.dump(fourier_results, f)\n",
    "\n",
    "    return fourier_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sell_prices의 각 행에서 NaN이 끝나고 처음으로 숫자인 column을 찾기\n",
    "def create_first_sales_column_dict(df, save_result=False):\n",
    "    first_sales_column_dict = {}\n",
    "    \n",
    "    for idx in df.index:\n",
    "        row = df.iloc[idx]\n",
    "        # state_id와 item_id로 키 튜플 생성\n",
    "        key = (row['state_id'], row['item_id'])\n",
    "        \n",
    "        # NaN 값들의 위치를 찾습니다\n",
    "        nan_mask = row.isna()\n",
    "        \n",
    "        if not nan_mask.any():\n",
    "            # NaN이 없는 경우 첫 번째 데이터 컬럼('d_1')을 저장\n",
    "            first_sales_column_dict[key] = 'd_1'\n",
    "        else:\n",
    "            # 마지막 NaN의 위치를 찾습니다\n",
    "            last_nan_idx = nan_mask[::-1].idxmax()\n",
    "            # 마지막 NaN의 위치 이후의 첫 번째 숫자가 있는 컬럼을 찾습니다\n",
    "            last_nan_position = row.index.get_loc(last_nan_idx)\n",
    "            first_number_col = row.index[last_nan_position + 1]\n",
    "            first_sales_column_dict[key] = first_number_col\n",
    "    \n",
    "    if save_result:\n",
    "        with open('../data/preprocessed/first_sales_column_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(first_sales_column_dict, f)\n",
    "            \n",
    "    return first_sales_column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# first_sales_column_dict = create_first_sales_column_dict(sell_prices, save_result==True)\n",
    "\n",
    "# 로드\n",
    "with open('../data/preprocessed/first_sales_column_dict.pkl', 'rb') as f:\n",
    "    first_sales_column_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_periods_with_fourier(sale, start_col, save_plot=False):\n",
    "    # ...existing code...\n",
    "    \n",
    "    # 주기 계산 및 중복 제거\n",
    "    raw_periods = [1/f for f in sorted_frequencies if 1/f < len(sale_values)//2]\n",
    "    \n",
    "    # 유사한 주기 병합 - 수정된 버전\n",
    "    merged_periods = []\n",
    "    merged_magnitudes = []\n",
    "    \n",
    "    if raw_periods:\n",
    "        # 주기와 진폭을 함께 정렬\n",
    "        period_magnitude_pairs = list(zip(raw_periods, sorted_magnitudes))\n",
    "        period_magnitude_pairs.sort(key=lambda x: x[1], reverse=True)  # 진폭 기준 내림차순 정렬\n",
    "        \n",
    "        for period, magnitude in period_magnitude_pairs:\n",
    "            period = int(round(period))\n",
    "            # 이미 존재하는 유사한 주기가 있는지 확인\n",
    "            similar_exists = any(abs(period - p) <= max(1, p * 0.05) for p in merged_periods)\n",
    "            \n",
    "            if not similar_exists:\n",
    "                merged_periods.append(period)\n",
    "                merged_magnitudes.append(magnitude)\n",
    "    \n",
    "    # 최종 결과 정렬\n",
    "    merged_periods = sorted(list(set(merged_periods)))\n",
    "    \n",
    "    # ...existing code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "fourier_results = analyze_period_with_fourier(sales, first_sales_column_dict, save_result=True, save_plot=False)\n",
    "\n",
    "# 로드\n",
    "with open('../data/fourier/results.pkl', 'rb') as f:\n",
    "    fourier_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sell_price_changes_with_log_differencing(sell_prices, first_sales_column_dict, save_result=False, save_plot=False):\n",
    "\n",
    "    # 데이터 복사\n",
    "    log_differenced_sell_prices = sell_prices.copy()\n",
    "\n",
    "    # 행별로 시작 컬럼부터 차분 수행\n",
    "    for idx, sell_price in sell_prices.iterrows():\n",
    "        # 시작 컬럼 가져오기\n",
    "        start_col = first_sales_column_dict.get(tuple(sell_price[:2]))\n",
    "        \n",
    "        # 시작 컬럼 이후 데이터 선택\n",
    "        start_index = sell_prices.columns.get_loc(start_col)\n",
    "        sell_price_values = np.array(sell_price.iloc[start_index:].values, dtype=np.float64)\n",
    "\n",
    "        # 로그 변환 및 차분 계산\n",
    "        logged_sell_price_values = np.log(sell_price_values + 1e-9)  # 로그 계산 시 0 방지\n",
    "        log_differenced_sell_price_values = np.diff(logged_sell_price_values, prepend=logged_sell_price_values[0])\n",
    "\n",
    "        # 결과 저장\n",
    "        log_differenced_sell_prices.iloc[idx, start_index:] = log_differenced_sell_price_values\n",
    "\n",
    "        # 시각화\n",
    "        if save_plot:\n",
    "            fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "            axs[0].plot(sell_price_values, label=f\"Original Sell Prices: {sell_price['state_id']}, {sell_price['item_id']}\")\n",
    "            axs[0].set_xlabel(\"Time\")\n",
    "            axs[0].set_ylabel(\"Sell Prices\")\n",
    "            axs[0].legend()\n",
    "\n",
    "            axs[1].plot(log_differenced_sell_price_values, label=f\"Log-Differenced Sell Prices: {sell_price['state_id']}, {sell_price['item_id']}\")\n",
    "            axs[1].set_xlabel(\"Time\")\n",
    "            axs[1].set_ylabel(\"Log-Differenced Sell Prices\")\n",
    "            axs[1].legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"../data/log_differencing/plot/{sell_price['state_id']}_{sell_price['item_id']}.png\")\n",
    "            plt.close()\n",
    "\n",
    "    if save_result:\n",
    "        log_differenced_sell_prices.to_csv(\"../data/log_differencing/log_differenced_sell_prices.csv\", index=False)\n",
    "\n",
    "    return log_differenced_sell_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# log_differenced_sell_prices = calculate_sell_price_changes_with_log_differencing(sell_prices, first_sales_column_dict, save_result=True, save_plot=True)\n",
    "\n",
    "# 로드\n",
    "log_differenced_sell_prices = pd.read_csv(\"../data/log_differencing/log_differenced_sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stl_decomposition(data, period):\n",
    "    \"\"\"STL 분해 수행 및 분석\"\"\"\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "    \n",
    "    stl = STL(data, period=period)\n",
    "    result = stl.fit()\n",
    "    \n",
    "    return {\n",
    "        'trend': result.trend,\n",
    "        'seasonal': result.seasonal,\n",
    "        'resid': result.resid,\n",
    "        'strength_of_seasonality': 1 - result.resid.var() / (result.seasonal + result.resid).var()\n",
    "    }\n",
    "\n",
    "def optimize_period_selection(data, periods, snr_threshold=10):\n",
    "    \"\"\"SNR 기반 최적 주기 선택\"\"\"\n",
    "    selected_periods = []\n",
    "    current_snr = 0\n",
    "    \n",
    "    for period in sorted(periods):\n",
    "        # 해당 주기로 신호 재구성\n",
    "        reconstructed = reconstruct_signal_with_period(data, period)\n",
    "        new_snr = calculate_snr(data, reconstructed)\n",
    "        \n",
    "        if new_snr - current_snr > snr_threshold:\n",
    "            selected_periods.append(period)\n",
    "            current_snr = new_snr\n",
    "            \n",
    "    return selected_periods\n",
    "\n",
    "def analyze_residual_periodicity(residuals):\n",
    "    \"\"\"잔차의 주기성 분석\"\"\"\n",
    "    fft = np.fft.fft(residuals)\n",
    "    frequencies = np.fft.fftfreq(len(residuals))\n",
    "    \n",
    "    # 주요 주파수 성분 식별\n",
    "    magnitude_threshold = np.percentile(np.abs(fft), 95)\n",
    "    significant_freqs = frequencies[np.abs(fft) > magnitude_threshold]\n",
    "    \n",
    "    return [1/freq for freq in significant_freqs if freq != 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
