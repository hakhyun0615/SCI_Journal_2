{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import highlight_print, reduce_memory\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mPreparing dataset for level 1\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 2\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 3\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 4\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 5\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 6\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 7\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 8\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 9\u001b[0m\n",
      "\u001b[93mPreparing dataset for level 10\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m         feature \u001b[38;5;241m=\u001b[39m nodes_df[nodes_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m node]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m] \u001b[38;5;66;03m# time x feature\u001b[39;00m\n\u001b[1;32m     57\u001b[0m         feature_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(feature))\n\u001b[0;32m---> 58\u001b[0m         target \u001b[38;5;241m=\u001b[39m nodes_df[\u001b[43mnodes_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales_sum\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m] \u001b[38;5;66;03m# time\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         target_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(target))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level, nodes \u001b[38;5;129;01min\u001b[39;00m level_to_node\u001b[38;5;241m.\u001b[39mitems(): \n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "levels = [\n",
    "    [],                        # Level 1: Total\n",
    "    ['state_id'],              # Level 2: State\n",
    "    ['store_id'],              # Level 3: Store\n",
    "    ['cat_id'],                # Level 4: Category\n",
    "    ['dept_id'],               # Level 5: Department\n",
    "    ['state_id', 'cat_id'],    # Level 6: State-Category\n",
    "    ['state_id', 'dept_id'],   # Level 7: State-Department\n",
    "    ['store_id', 'cat_id'],    # Level 8: Store-Category\n",
    "    ['store_id', 'dept_id'],   # Level 9: Store-Department\n",
    "    ['item_id'],               # Level 10: Item\n",
    "    ['item_id', 'state_id'],   # Level 11: Item-State\n",
    "    ['item_id', 'store_id']    # Level 12: Item-Store\n",
    "]\n",
    "\n",
    "node_list = []\n",
    "level_to_node = {}\n",
    "node_to_idx = {}\n",
    "level_to_idx = {}\n",
    "\n",
    "feature_list = [] # node x time x feature\n",
    "target_list = [] # node x time\n",
    "\n",
    "for level_idx, level in enumerate(levels, start=1):\n",
    "    highlight_print(f\"Preparing dataset for level {level_idx}\")\n",
    "    datasets = {'train': {}, 'valid': {}, 'test': {}}\n",
    "\n",
    "    agg_df = pd.read_csv(f'../../data/preprocessed/agg_df_level_{level_idx}.csv')\n",
    "    calendar_df = pd.read_csv('../../data/preprocessed/calendar_df.csv')\n",
    "\n",
    "    agg_df = reduce_memory(agg_df)\n",
    "    calendar_df = reduce_memory(calendar_df)\n",
    "\n",
    "    start_date = pd.to_datetime('2011-01-29')\n",
    "    valid_start_date = pd.to_datetime('2016-03-28')\n",
    "    agg_df['d'] = agg_df['d'].apply(lambda x: int(x.split('_')[1]) - 1)\n",
    "    agg_df['d'] = start_date + pd.to_timedelta(agg_df['d'], unit='D')\n",
    "    calendar_df['d'] = calendar_df['d'].apply(lambda x: int(x.split('_')[1]) - 1)\n",
    "    calendar_df['d'] = start_date + pd.to_timedelta(calendar_df['d'], unit='D')\n",
    "    \n",
    "    if len(level) == 0:\n",
    "        agg_df.insert(1, 'id', 'total')\n",
    "    elif len(level) == 1: \n",
    "        agg_df.insert(1, 'id', agg_df[level[0]])\n",
    "        del agg_df[level[0]]\n",
    "    elif len(level) > 1:\n",
    "        agg_df.insert(1, 'id', agg_df[level[0]] + '_' + agg_df[level[1]])\n",
    "        del agg_df[level[0]]\n",
    "        del agg_df[level[1]]\n",
    "\n",
    "    nodes = agg_df['id'].unique()\n",
    "    level_to_node[level_idx] = nodes\n",
    "    \n",
    "    nodes_df = agg_df.merge(calendar_df, on=\"d\", how=\"left\")\n",
    "    for node in nodes:\n",
    "        feature = nodes_df[nodes_df['id'] == node].drop(columns=['level', 'id', 'd']).values[:-9] # time x feature\n",
    "        feature_list.append(np.array(feature))\n",
    "        target = nodes_df[nodes_df['id'] == node]['sales_sum'].values[:-9] # time\n",
    "        target_list.append(np.array(target))\n",
    "\n",
    "for level, nodes in level_to_node.items(): \n",
    "    level_to_idx[level] = []\n",
    "    for node in nodes:\n",
    "        node_to_idx[node] = len(node_list)\n",
    "        node_list.append(node)\n",
    "        level_to_idx[level].append(node_to_idx[node])\n",
    "\n",
    "windowed_feature_list = [] # num window x node x feature x window_size\n",
    "windowed_target_list = [] # num window x node x window_size\n",
    "\n",
    "window_size = 28\n",
    "num_window = feature_list[0].shape[0] // window_size\n",
    "\n",
    "for window_idx in range(num_window):\n",
    "    window_feature = [] # node x window_size x feature\n",
    "    for node_idx in range(len(feature_list)):\n",
    "        feature = feature_list[node_idx][window_idx*window_size:(window_idx+1)*window_size] # window size x feature\n",
    "        window_feature.append(feature)\n",
    "    window_feature = np.array(window_feature)\n",
    "    window_feature = np.transpose(window_feature, (0, 2, 1)) # node x feature x window_size\n",
    "    windowed_feature_list.append(window_feature)\n",
    "    \n",
    "    window_target = [] # node x window_size\n",
    "    for node_idx in range(len(target_list)):\n",
    "        target = target_list[node_idx][(window_idx+1)*window_size:(window_idx+2)*window_size]  # window size\n",
    "        window_target.append(target)\n",
    "    window_target = np.array(window_target)\n",
    "    windowed_target_list.append(window_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NetworkX 그래프\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 노드 추가\n",
    "for node, idx in node_to_idx.items():\n",
    "    G.add_node(idx, name=node)\n",
    "\n",
    "# 엣지 추가\n",
    "# 지리적 계층\n",
    "if 1 in level_to_idx and 2 in level_to_idx:  # Total <-> State\n",
    "    total_idx = level_to_idx[1][0]\n",
    "    for state_idx in level_to_idx[2]:\n",
    "        G.add_edge(total_idx, state_idx, type='geo_hierarchy', direction='down')\n",
    "        G.add_edge(state_idx, total_idx, type='geo_hierarchy', direction='up')\n",
    "\n",
    "if 2 in level_to_idx and 3 in level_to_idx:  # State <-> Store\n",
    "    for state_idx in level_to_idx[2]:\n",
    "        state_name = node_list[state_idx]\n",
    "        for store_idx in level_to_idx[3]:\n",
    "            store_name = node_list[store_idx]\n",
    "            if store_name.startswith(state_name):\n",
    "                G.add_edge(state_idx, store_idx, type='geo_hierarchy', direction='down')\n",
    "                G.add_edge(store_idx, state_idx, type='geo_hierarchy', direction='up')\n",
    "\n",
    "# 상품 계층\n",
    "if 1 in level_to_idx and 4 in level_to_idx:  # Total <-> Category\n",
    "    total_idx = level_to_idx[1][0]\n",
    "    for cat_idx in level_to_idx[4]:\n",
    "        G.add_edge(total_idx, cat_idx, type='prod_hierarchy', direction='down')\n",
    "        G.add_edge(cat_idx, total_idx, type='prod_hierarchy', direction='up')\n",
    "\n",
    "if 4 in level_to_idx and 5 in level_to_idx:  # Category <-> Department\n",
    "    for cat_idx in level_to_idx[4]:\n",
    "        cat_name = node_list[cat_idx]\n",
    "        for dept_idx in level_to_idx[5]:\n",
    "            dept_name = node_list[dept_idx]\n",
    "            if dept_name.startswith(cat_name):\n",
    "                G.add_edge(cat_idx, dept_idx, type='prod_hierarchy', direction='down')\n",
    "                G.add_edge(dept_idx, cat_idx, type='prod_hierarchy', direction='up')\n",
    "\n",
    "if 5 in level_to_idx and 10 in level_to_idx:  # Department <-> Item\n",
    "    for dept_idx in level_to_idx[5]:\n",
    "        dept_name = node_list[dept_idx]\n",
    "        for item_idx in level_to_idx[10]:\n",
    "            item_name = node_list[item_idx]\n",
    "            if dept_name.startswith(item_name):\n",
    "                G.add_edge(dept_idx, item_idx, type='prod_hierarchy', direction='down')\n",
    "                G.add_edge(item_idx, dept_idx, type='prod_hierarchy', direction='up')\n",
    "\n",
    "# 결합 계층\n",
    "if 2 in level_to_idx and 6 in level_to_idx: # State <-> State x Category\n",
    "    for state_idx in level_to_idx[2]:\n",
    "        state_name = node_list[state_idx]\n",
    "        for state_cat_idx in level_to_idx[6]:\n",
    "            state_cat_name = node_list[state_cat_idx]\n",
    "            if state_cat_name.startswith(state_name):\n",
    "                G.add_edge(state_idx, state_cat_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(state_cat_idx, state_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 4 in level_to_idx and 6 in level_to_idx: # Category <-> State x Category\n",
    "    for cat_idx in level_to_idx[4]:\n",
    "        cat_name = node_list[cat_idx]\n",
    "        for state_cat_idx in level_to_idx[6]:\n",
    "            state_cat_name = node_list[state_cat_idx]\n",
    "            if state_cat_name.endswith(cat_name):\n",
    "                G.add_edge(cat_idx, state_cat_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(state_cat_idx, cat_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 2 in level_to_idx and 7 in level_to_idx: # State <-> State x Department\n",
    "    for state_idx in level_to_idx[2]:\n",
    "        state_name = node_list[state_idx]\n",
    "        for state_dept_idx in level_to_idx[7]:\n",
    "            state_dept_name = node_list[state_dept_idx]\n",
    "            if state_dept_name.startswith(state_name):\n",
    "                G.add_edge(state_idx, state_dept_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(state_dept_idx, state_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 5 in level_to_idx and 7 in level_to_idx: # Department <-> State x Department\n",
    "    for dept_idx in level_to_idx[5]:\n",
    "        dept_name = node_list[dept_idx]\n",
    "        for state_dept_idx in level_to_idx[7]:\n",
    "            state_dept_name = node_list[state_dept_idx]\n",
    "            if state_dept_name.endswith(dept_name):\n",
    "                G.add_edge(dept_idx, state_dept_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(state_dept_idx, dept_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 2 in level_to_idx and 11 in level_to_idx: # State <-> State x Item\n",
    "    for state_idx in level_to_idx[2]:\n",
    "        state_name = node_list[state_idx]\n",
    "        for item_state_idx in level_to_idx[11]:\n",
    "            item_state_name = node_list[item_state_idx]\n",
    "            if item_state_name.endswith(state_name):\n",
    "                G.add_edge(state_idx, item_state_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(item_state_idx, state_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 10 in level_to_idx and 11 in level_to_idx: # Item <-> State x Item\n",
    "    for item_idx in level_to_idx[10]:\n",
    "        item_name = node_list[item_idx]\n",
    "        for item_state_idx in level_to_idx[11]:\n",
    "            item_state_name = node_list[item_state_idx]\n",
    "            if item_state_name.startswith(item_name):\n",
    "                G.add_edge(item_idx, item_state_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(item_state_idx, item_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 3 in level_to_idx and 8 in level_to_idx: # Store <-> Store x Category\n",
    "    for store_idx in level_to_idx[3]:\n",
    "        store_name = node_list[store_idx]\n",
    "        for store_cat_idx in level_to_idx[8]:\n",
    "            store_cat_name = node_list[store_cat_idx]\n",
    "            if store_cat_name.startswith(store_name):\n",
    "                G.add_edge(store_idx, store_cat_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(store_cat_idx, store_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 4 in level_to_idx and 8 in level_to_idx: # Category <-> Store x Category\n",
    "    for cat_idx in level_to_idx[4]:\n",
    "        cat_name = node_list[cat_idx]\n",
    "        for store_cat_idx in level_to_idx[8]:\n",
    "            store_cat_name = node_list[store_cat_idx]\n",
    "            if store_cat_name.endswith(cat_name):\n",
    "                G.add_edge(cat_idx, store_cat_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(store_cat_idx, cat_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 3 in level_to_idx and 9 in level_to_idx: # Store <-> Store x Department\n",
    "    for store_idx in level_to_idx[3]:\n",
    "        store_name = node_list[store_idx]\n",
    "        for store_dept_idx in level_to_idx[9]:\n",
    "            store_dept_name = node_list[store_dept_idx]\n",
    "            if store_dept_name.startswith(store_name):\n",
    "                G.add_edge(store_idx, store_dept_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(store_dept_idx, store_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 5 in level_to_idx and 9 in level_to_idx: # Department <-> Store x Department\n",
    "    for dept_idx in level_to_idx[5]:\n",
    "        dept_name = node_list[dept_idx]\n",
    "        for store_dept_idx in level_to_idx[7]:\n",
    "            store_dept_name = node_list[store_dept_idx]\n",
    "            if store_dept_name.endswith(dept_name):\n",
    "                G.add_edge(dept_idx, store_dept_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(store_dept_idx, dept_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 3 in level_to_idx and 12 in level_to_idx: # Store <-> Store x Item\n",
    "    for store_idx in level_to_idx[3]:\n",
    "        store_name = node_list[store_idx]\n",
    "        for item_store_idx in level_to_idx[12]:\n",
    "            item_store_name = node_list[item_store_idx]\n",
    "            if item_store_name.endswith(store_name):\n",
    "                G.add_edge(store_idx, item_store_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(item_store_idx, store_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "if 10 in level_to_idx and 12 in level_to_idx: # Item <-> Store x Item\n",
    "    for item_idx in level_to_idx[10]:\n",
    "        item_name = node_list[item_idx]\n",
    "        for item_store_idx in level_to_idx[12]:\n",
    "            item_store_name = node_list[item_store_idx]\n",
    "            if item_store_name.startswith(item_name):\n",
    "                G.add_edge(item_idx, item_store_idx, type='agg_hierarchy', direction='down')\n",
    "                G.add_edge(item_store_idx, item_idx, type='agg_hierarchy', direction='up')\n",
    "\n",
    "# 크로스 계층\n",
    "if 6 in level_to_idx and 7 in level_to_idx: # State x Category <-> State x Department\n",
    "    for state_cat_idx in level_to_idx[6]:\n",
    "        state_cat_name = node_list[state_cat_idx]\n",
    "        for state_dept_idx in level_to_idx[7]:\n",
    "            state_dept_name = node_list[state_dept_idx]\n",
    "            if state_dept_name.startswith(state_cat_name):\n",
    "                G.add_edge(state_cat_idx, state_dept_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(state_dept_idx, state_cat_idx, type='cross_hierarchy', direction='up')\n",
    "\n",
    "if 7 in level_to_idx and 11 in level_to_idx: # State x Department <-> State x Item\n",
    "    for state_dept_idx in level_to_idx[7]:\n",
    "        state_dept_name = node_list[state_dept_idx]\n",
    "        state_dept_parts = state_dept_name.split('_')\n",
    "        state = state_dept_parts[0]\n",
    "        dept = '_'.join(state_dept_parts[1:])\n",
    "        for state_item_idx in level_to_idx[11]:\n",
    "            state_item_name = node_list[state_item_idx]\n",
    "            state_item_parts = state_item_name.split('_')\n",
    "            item_dept = state_item_parts[0] + '_' + state_item_parts[1]\n",
    "            item_state = state_item_parts[-1]\n",
    "            if dept == item_dept and state == item_state:\n",
    "                G.add_edge(state_dept_idx, state_item_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(state_item_idx, state_dept_idx, type='cross_hierarchy', direction='up')\n",
    "\n",
    "if 8 in level_to_idx and 9 in level_to_idx: # Store x Category <-> Store x Department\n",
    "    for store_cat_idx in level_to_idx[8]:\n",
    "        store_cat_name = node_list[store_cat_idx]\n",
    "        for store_dept_idx in level_to_idx[9]:\n",
    "            store_dept_name = node_list[store_dept_idx]\n",
    "            if store_dept_name.startswith(store_cat_name):\n",
    "                G.add_edge(store_cat_idx, store_dept_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(store_dept_idx, store_cat_idx, type='cross_hierarchy', direction='up')\n",
    "\n",
    "if 9 in level_to_idx and 12 in level_to_idx: # Store x Department <-> Store x Item\n",
    "    for store_dept_idx in level_to_idx[9]:  \n",
    "        store_dept_name = node_list[store_dept_idx]  \n",
    "        store_dept_parts = store_dept_name.split('_')\n",
    "        store = store_dept_parts[0] + '_' + store_dept_parts[1]     \n",
    "        dept = store_dept_parts[2] + '_' + store_dept_parts[3]     \n",
    "        for item_store_idx in level_to_idx[12]: \n",
    "            item_store_name = node_list[item_store_idx]\n",
    "            item_store_parts = item_store_name.split('_')\n",
    "            item_dept = item_store_parts[0] + '_' + item_store_parts[1]\n",
    "            item_store = item_store_parts[3] + '_' + item_store_parts[4]    \n",
    "            if dept == item_dept and store == item_store:\n",
    "                G.add_edge(store_dept_idx, item_store_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(item_store_idx, store_dept_idx, type='cross_hierarchy', direction='up')\n",
    "\n",
    "if 6 in level_to_idx and 8 in level_to_idx: # State x Category <-> Store x Category\n",
    "    for state_cat_idx in level_to_idx[6]:\n",
    "        state_cat_name = node_list[state_cat_idx]\n",
    "        state_cat_parts = state_cat_name.split('_')\n",
    "        state = state_cat_parts[0]\n",
    "        category = state_cat_parts[1]\n",
    "        for store_cat_idx in level_to_idx[7]:\n",
    "            store_cat_name = node_list[store_cat_idx]\n",
    "            store_cat_parts = store_cat_name.split('_')\n",
    "            store_state = store_cat_parts[0]\n",
    "            store_category = store_cat_parts[2]\n",
    "            if state == store_state and category == store_category:\n",
    "                G.add_edge(state_cat_idx, store_cat_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(store_cat_idx, state_cat_idx, type='cross_hierarchy', direction='up')\n",
    "\n",
    "if 7 in level_to_idx and 9 in level_to_idx: # State x Department <-> Store x Department\n",
    "    for state_dept_idx in level_to_idx[7]:\n",
    "        state_dept_name = node_list[state_dept_idx]\n",
    "        state_dept_parts = state_dept_name.split('_')\n",
    "        state = state_dept_parts[0]          \n",
    "        dept = state_dept_parts[1] + '_' + state_dept_parts[2]\n",
    "        for store_dept_idx in level_to_idx[9]:\n",
    "            store_dept_name = node_list[store_dept_idx]\n",
    "            store_dept_parts = store_dept_name.split('_')\n",
    "            store_state = store_dept_parts[0]     \n",
    "            store_dept = store_dept_parts[2] + '_' + store_dept_parts[3]\n",
    "            if state == store_state and dept == store_dept:\n",
    "                G.add_edge(state_dept_idx, store_dept_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(store_dept_idx, state_dept_idx, type='cross_hierarchy', direction='up')\n",
    "\n",
    "if 11 in level_to_idx and 12 in level_to_idx: # Item x State <-> Item x Store\n",
    "    for item_state_idx in level_to_idx[11]:\n",
    "        item_state_name = node_list[item_state_idx]\n",
    "        for item_store_idx in level_to_idx[12]: \n",
    "            item_store_name = node_list[item_store_idx]\n",
    "            if item_store_name.startswith(item_state_name):\n",
    "                G.add_edge(item_state_idx, item_store_idx, type='cross_hierarchy', direction='down')\n",
    "                G.add_edge(item_store_idx, item_state_idx, type='cross_hierarchy', direction='up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(G.edges())\n",
    "edge_index = np.array([[u, v] for u, v in edge_list]).T\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "dataset = StaticGraphTemporalSignal(\n",
    "    edge_index=edge_index,\n",
    "    features=windowed_feature_list,\n",
    "    targets=windowed_target_list\n",
    ")\n",
    "\n",
    "for snapshot_idx, snapshot in enumerate(dataset):\n",
    "    x = snapshot.x  # 형태: [노드 수, 피쳐 수, window_size]\n",
    "    y = snapshot.y  # 형태: [노드 수, window_size]\n",
    "    edge_index = snapshot.edge_index\n",
    "    \n",
    "    print(f\"Snapshot {snapshot_idx}:\")\n",
    "    print(f\"  Node features shape: {x.shape}\")\n",
    "    print(f\"  Target shape: {y.shape}\")\n",
    "    print(f\"  Edge index shape: {edge_index.shape}\")\n",
    "    \n",
    "    # 이제 이 데이터로 모델 학습/예측 등의 작업 수행\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_idx = []\n",
    "edge_type = []\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    edge_idx.append([u, v])\n",
    "        \n",
    "    if data['type'] == 'geo_hierarchy':\n",
    "        type_idx = 0\n",
    "    elif data['type'] == 'prod_hierarchy':\n",
    "        type_idx = 1\n",
    "    elif data['type'] == 'agg_hierarchy':\n",
    "        type_idx = 2\n",
    "    elif data['type'] == 'cross_hierarchy':\n",
    "        type_idx = 3\n",
    "    edge_type.append(type_idx)\n",
    "\n",
    "edge_idx = torch.tensor(edge_idx, dtype=torch.long).t().contiguous()\n",
    "edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
    "\n",
    "x = []\n",
    "for i in range(len(G.nodes())):\n",
    "    x.append(idx_to_forecast[i])\n",
    "x = torch.stack(x)\n",
    "\n",
    "# PyG Data 객체\n",
    "pyg_data = Data(x=x, edge_index=edge_idx, edge_type=edge_type)\n",
    "pyg_data.num_nodes = len(G.nodes())\n",
    "pyg_data.num_edge_types = len(set(edge_type.numpy().tolist()))\n",
    "\n",
    "torch.save(pyg_data, '../dataset/graph/pyg_data.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
