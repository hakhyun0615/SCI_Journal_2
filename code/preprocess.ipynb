{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import reduce_memory\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir = '../data/original'\n",
    "save_data_dir = '../data/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(f'{input_data_dir}/sales_train_evaluation.csv')\n",
    "sell_prices = pd.read_csv(f'{input_data_dir}/sell_prices.csv')\n",
    "calendar = pd.read_csv(f'{input_data_dir}/calendar.csv')\n",
    "\n",
    "# reduce memory usage\n",
    "sales = reduce_memory(sales)\n",
    "sell_prices = reduce_memory(sell_prices)\n",
    "calendar = reduce_memory(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "calendar = calendar[calendar['d'].apply(lambda x: int(x.split('_')[1]) <= 1941)]\n",
    "\n",
    "# \n",
    "calendar.date = pd.to_datetime(calendar.date)\n",
    "calendar['year_delta'] = calendar.year - 2011\n",
    "\n",
    "# cyclic encodings\n",
    "calendar['quarter_sin'] = np.sin(2 * np.pi * calendar.date.dt.quarter/4.0)\n",
    "calendar['quarter_cos'] = np.cos(2 * np.pi * calendar.date.dt.quarter/4.0)\n",
    "calendar['month_sin'] = np.sin(2 * np.pi * calendar.month/12.0)\n",
    "calendar['month_cos'] = np.cos(2 * np.pi * calendar.month/12.0)\n",
    "calendar['day_sin'] = np.sin(2 * np.pi * calendar.date.dt.day/calendar.date.dt.days_in_month)\n",
    "calendar['day_cos'] = np.cos(2 * np.pi * calendar.date.dt.day/calendar.date.dt.days_in_month)\n",
    "calendar['weekday_sin'] = np.sin(2 * np.pi * calendar.wday/7.0)\n",
    "calendar['weekday_cos'] = np.cos(2 * np.pi * calendar.wday/7.0)\n",
    "\n",
    "# event count\n",
    "calendar['event_count'] = calendar[['event_name_1', 'event_name_2']].notna().sum(axis=1)\n",
    "\n",
    "# event encodings\n",
    "event_names = ['event_name_1', 'event_name_2']\n",
    "event_names_enc = ['event_name_1_enc', 'event_name_2_enc']\n",
    "calendar[event_names_enc] = calendar[event_names]\n",
    "event_names_encoder = ce.OrdinalEncoder(cols=event_names_enc)\n",
    "event_names_encoder.fit(calendar)\n",
    "event_names_encoder.mapping[1]['mapping'] = event_names_encoder.mapping[0]['mapping']\n",
    "calendar = event_names_encoder.transform(calendar)\n",
    "for col in event_names_enc:\n",
    "    calendar[col] = calendar[col] - 1\n",
    "\n",
    "event_types = ['event_type_1', 'event_type_2']\n",
    "event_types_enc = ['event_type_1_enc', 'event_type_2_enc']\n",
    "calendar[event_types_enc] = calendar[event_types]\n",
    "event_type_encoder = ce.OrdinalEncoder(cols=event_types_enc)\n",
    "event_type_encoder.fit(calendar)\n",
    "event_type_encoder.mapping[1]['mapping'] = event_type_encoder.mapping[0]['mapping']\n",
    "calendar = event_type_encoder.transform(calendar)\n",
    "for col in event_types_enc:\n",
    "    calendar[col] = calendar[col] - 1\n",
    "\n",
    "#\n",
    "calendar_df = calendar[['wm_yr_wk', 'd', 'snap_CA', 'snap_TX', 'snap_WI', 'year_delta',\n",
    "                        'quarter_sin', 'quarter_cos', 'month_sin', 'month_cos', \n",
    "                        'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos', 'event_count']\n",
    "                        + event_names_enc \n",
    "                        + event_types_enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt\n",
    "sales = pd.melt(sales, id_vars=['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_vars=['d_'+str(i) for i in range(1, 1942)], value_name='sales')\n",
    "\n",
    "# merge\n",
    "data_df = sales.merge(right=calendar_df[['d', 'wm_yr_wk']], on=['d'], how='left')\n",
    "\n",
    "# id\n",
    "data_df.insert(0, 'id', data_df['store_id'] + '_' + data_df['item_id'])\n",
    "\n",
    "# out of stock\n",
    "def calculate_out_of_stock(group):\n",
    "    first_sale = group[group['sales'] > 0].index.min()\n",
    "    group['out_of_stock'] = 0\n",
    "    if not pd.isna(first_sale):\n",
    "        group.loc[first_sale:, 'out_of_stock'] = ((group.loc[first_sale:, 'sales'] == 0).astype(int).groupby((group.loc[first_sale:, 'sales'] != 0).cumsum()).cumsum())\n",
    "        group['out_of_stock'] = group['out_of_stock'].where(group['sales'] == 0, 0)    \n",
    "    return group\n",
    "data_df = data_df.groupby('id').apply(calculate_out_of_stock).reset_index(drop=True)\n",
    "\n",
    "# diff\n",
    "data_df['sales_diff'] = data_df.groupby('id')['sales'].diff().fillna(0)\n",
    "\n",
    "# lag\n",
    "data_df['sales_lag1'] = data_df.groupby('id')['sales'].shift(1).fillna(0)\n",
    "data_df['sales_lag7'] = data_df.groupby('id')['sales'].shift(7).fillna(0)\n",
    "data_df['sales_lag28'] = data_df.groupby('id')['sales'].shift(28).fillna(0)\n",
    "                                                                         \n",
    "# rolling\n",
    "data_df['sales_rolling7'] = data_df.groupby('id')['sales'].rolling(window=7).mean().fillna(0).reset_index(drop=True)\n",
    "data_df['sales_rolling28'] = data_df.groupby('id')['sales'].rolling(window=28).mean().fillna(0).reset_index(drop=True)\n",
    "\n",
    "# rolling diff\n",
    "data_df['sales_rolling7_diff'] = data_df.groupby('id')['sales'].rolling(window=7).mean().diff().fillna(0).reset_index(drop=True)\n",
    "data_df['sales_rolling28_diff'] = data_df.groupby('id')['sales'].rolling(window=28).mean().diff().fillna(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id\n",
    "sell_prices.insert(0, 'id', sell_prices['store_id'] + '_' + sell_prices['item_id'])\n",
    "\n",
    "# release week\n",
    "release = sell_prices.groupby('id')['wm_yr_wk'].min().reset_index()\n",
    "release['release'] = 1\n",
    "sell_prices['release'] = 0\n",
    "sell_prices.loc[sell_prices.set_index(['id', 'wm_yr_wk']).index.isin(release.set_index(['id', 'wm_yr_wk']).index), 'release'] = 1\n",
    "\n",
    "# relative sell price in store by week\n",
    "sell_prices['sell_price_in_store'] = sell_prices['sell_price'] / sell_prices.groupby(['store_id', 'wm_yr_wk'])['sell_price'].transform('mean')\n",
    "\n",
    "# diff\n",
    "sell_prices['sell_price_diff'] = sell_prices.groupby('id')['sell_price'].diff().fillna(0)\n",
    "\n",
    "# lag\n",
    "sell_prices['sell_price_lag'] = sell_prices.groupby('id')['sell_price'].shift(1).fillna(0)\n",
    "\n",
    "# rolling\n",
    "sell_prices['sell_price_rolling'] = sell_prices.groupby('id')['sell_price'].rolling(window=4).mean().fillna(0).reset_index(drop=True)\n",
    "\n",
    "# rolling diff\n",
    "sell_prices['sell_price_rolling_diff'] = sell_prices.groupby('id')['sell_price'].rolling(window=4).mean().diff().fillna(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "data_df = data_df.merge(right=sell_prices[['id', 'item_id', 'store_id', 'wm_yr_wk', 'sell_price', 'release', 'sell_price_in_store', 'sell_price_diff', 'sell_price_lag', 'sell_price_rolling', 'sell_price_rolling_diff']], on=['id', 'item_id', 'store_id', 'wm_yr_wk'], how='left')\n",
    "\n",
    "# accumulate after release day\n",
    "def accumulate_after_release(group):\n",
    "    group = group.reset_index(drop=True)\n",
    "    release = group[group['release'] == 1].index.min()\n",
    "    group.loc[release:, 'release'] = range(1, len(group) - release + 1)\n",
    "    return group\n",
    "data_df = data_df.groupby('id').apply(accumulate_after_release).reset_index(drop=True)\n",
    "\n",
    "# fill nan(before release) with 0 \n",
    "data_df = data_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "del calendar_df['wm_yr_wk']\n",
    "calendar_df.to_csv(f'{save_data_dir}/calendar_df.csv', index=False)\n",
    "\n",
    "#\n",
    "del data_df['id']\n",
    "del data_df['wm_yr_wk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [15:25<00:00, 77.14s/it]\n"
     ]
    }
   ],
   "source": [
    "levels = [\n",
    "    [],                        # Level 1: Total\n",
    "    ['state_id'],              # Level 2: State\n",
    "    ['store_id'],              # Level 3: Store\n",
    "    ['cat_id'],                # Level 4: Category\n",
    "    ['dept_id'],               # Level 5: Department\n",
    "    ['state_id', 'cat_id'],    # Level 6: State-Category\n",
    "    ['state_id', 'dept_id'],   # Level 7: State-Department\n",
    "    ['store_id', 'cat_id'],    # Level 8: Store-Category\n",
    "    ['store_id', 'dept_id'],   # Level 9: Store-Department\n",
    "    ['item_id'],               # Level 10: Item\n",
    "    ['item_id', 'state_id'],   # Level 11: Item-State\n",
    "    ['item_id', 'store_id']    # Level 12: Individual\n",
    "]\n",
    "\n",
    "agg_funcs = {\n",
    "    'sales': [ \n",
    "        ('sales_sum', 'sum'), # 판매량 합계\n",
    "        ('sales_mean', 'mean'), # 판매량 평균값\n",
    "        ('sales_std', 'std'), # 판매량 표준편차\n",
    "        ('sales_max', 'max'), # 판매량 최대값\n",
    "        ('sales_min', 'min'), # 판매량 최소값\n",
    "     ],\n",
    "    'sales_diff': [('sales_diff_mean', 'mean')], # 판매량 변화량 평균값\n",
    "    'sales_lag1': [('sales_lag1_mean', 'mean')], # 1일 전 판매량 평균값\n",
    "    'sales_lag7': [('sales_lag7_mean', 'mean')], # 7일 전 판매량 평균값\n",
    "    'sales_lag28': [('sales_lag28_mean', 'mean')], # 28일 전 판매량 평균값\n",
    "    'sales_rolling7': [('sales_rolling7_mean', 'mean')], # 7일 판매량 이동평균 평균값\n",
    "    'sales_rolling28': [('sales_rolling28_mean', 'mean')], # 28일 판매량 이동평균 평균값\n",
    "    'sales_rolling7_diff': [('sales_rolling7_diff_mean', 'mean')], # 7일 판매량 이동평균 변화량 평균값\n",
    "    'sales_rolling28_diff': [('sales_rolling28_diff_mean', 'mean')], # 28일 판매량 이동평균 변화량 평균값\n",
    "\n",
    "    'release': [('release_mean', 'mean')], # 최초 판매량의 평균값\n",
    "    'out_of_stock': [('out_of_stock_mean', 'mean')], # 재고 없음 평균값\n",
    "\n",
    "    'sell_price': [\n",
    "        ('sell_price_mean', 'mean'), # 판매가격 평균값\n",
    "        ('sell_price_std', 'std'), # 판매가격 표준편차\n",
    "        ('sell_price_max', 'max'), # 판매가격 최대값\n",
    "        ('sell_price_min', 'min'), # 판매가격 최소값\n",
    "    ],\n",
    "    'sell_price_diff': [('sell_price_diff_mean', 'mean')], # 판매가격 변화량 평균값\n",
    "    'sell_price_lag': [('sell_price_lag_mean', 'mean')], # 1주 전 판매가격 평균값\n",
    "    'sell_price_rolling': [('sell_price_rolling_mean', 'mean')], # 1달 판매가격 이동평균 평균값\n",
    "    'sell_price_rolling_diff': [('sell_price_rolling_diff_mean', 'mean')], # 1달 판매가격 이동평균 변화량 평균값\n",
    "    'sell_price_in_store': [('sell_price_in_store_mean', 'mean')], # 매장 안에서의 상대적 판매 가격 평균값\n",
    "}\n",
    "\n",
    "for level_idx, level in tqdm(enumerate(levels, start=1), total=len(levels)):\n",
    "    if level_idx != 12:\n",
    "        continue\n",
    "    agg_cols = level + ['d'] if level else ['d']\n",
    "    agg_df = data_df.groupby(agg_cols).agg(**{\n",
    "        new_col: (col, func) \n",
    "        for col, aggs in agg_funcs.items() \n",
    "        for new_col, func in aggs\n",
    "    }).reset_index()\n",
    "\n",
    "    agg_df = agg_df.fillna(0)\n",
    "\n",
    "    agg_df['sort_key'] = agg_df['d'].str[2:].astype(int)\n",
    "    agg_df = agg_df.sort_values(['sort_key'] + level)\n",
    "    agg_df = agg_df.drop(columns=['sort_key']).reset_index(drop=True)\n",
    "    \n",
    "    agg_df.insert(0, 'level', level_idx)\n",
    "    agg_df.to_csv(f'{save_data_dir}/agg_df_level_{level_idx}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
