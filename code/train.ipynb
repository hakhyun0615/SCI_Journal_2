{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import mxnet as mx\n",
    "from gluonts.mx import Trainer\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.core.component import validated\n",
    "from gluonts.mx.trainer.callback import Callback\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "mx.random.seed(0)\n",
    "\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(Callback):\n",
    "    def __init__(self, patience: int = 10):\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.wait_count = 0\n",
    "        \n",
    "    def on_validation_epoch_end(\n",
    "        self,\n",
    "        epoch_no: int,\n",
    "        epoch_loss: float,\n",
    "        training_network: mx.gluon.HybridBlock,\n",
    "        trainer: mx.gluon.Trainer,\n",
    "    ) -> bool:\n",
    "        if epoch_loss < self.best_loss:\n",
    "            self.best_loss = epoch_loss\n",
    "            self.wait_count = 0\n",
    "        else:\n",
    "            self.wait_count += 1\n",
    "            \n",
    "        if self.wait_count >= self.patience:\n",
    "            print(f\"\\nEarly stopping triggered\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "class EarlyStoppingTrainer(Trainer):\n",
    "    @validated()\n",
    "    def __init__(self, patience: int = 10, **kwargs):\n",
    "        callbacks = kwargs.get('callbacks', [])\n",
    "        callbacks.append(EarlyStoppingCallback(patience=patience))\n",
    "        kwargs['callbacks'] = callbacks\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(epochs, learning_rate):\n",
    "    # save path\n",
    "    save_dir = f'../result/epochs_{epochs}-learning_rate_{learning_rate}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for level_idx in range(1, 13):\n",
    "        # level path\n",
    "        level_dir = os.path.join(save_dir, f'level_{level_idx}')\n",
    "        os.makedirs(level_dir, exist_ok=True)\n",
    "\n",
    "        estimators = create_estimators(\n",
    "                        level_idx=level_idx, \n",
    "                        train_dataset=dataset['train']\n",
    "                    )\n",
    "        highlight_print(f\"Level {level_idx}: Loading dataset\")\n",
    "        if estimators == 'TFT':\n",
    "            with open(os.path.join('../dataset/tft', f'dataset_level_{level_idx}.pkl'), 'rb') as f:\n",
    "                dataset = pickle.load(f)\n",
    "        else:\n",
    "            with open(os.path.join('../dataset/else', f'dataset_level_{level_idx}.pkl'), 'rb') as f:\n",
    "                dataset = pickle.load(f)\n",
    "\n",
    "        for estimator_name, estimator in estimators.items():\n",
    "            # estimator path\n",
    "            estimator_dir = os.path.join(level_dir, estimator_name)\n",
    "            os.makedirs(estimator_dir, exist_ok=True)\n",
    "\n",
    "            highlight_print(f\"Level {level_idx}: Training {estimator_name}\")\n",
    "            estimator.trainer = EarlyStoppingTrainer(\n",
    "                epochs=epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                num_batches_per_epoch=get_optimal_num_batches(mx.context.num_gpus()),\n",
    "                patience=10\n",
    "            )\n",
    "            predictor = estimator.train(\n",
    "                            training_data=dataset['train'],\n",
    "                            validation_data=dataset['test']\n",
    "                        )\n",
    "            predictor.serialize(Path(f\"{level_dir}/{estimator_name}\"))\n",
    "\n",
    "            highlight_print(f\"Level {level_idx}: Making predictions\")\n",
    "            train_forecasts_it, train_labels_it = make_evaluation_predictions(\n",
    "                dataset=dataset['train'],\n",
    "                predictor=predictor,\n",
    "            )\n",
    "            train_forecasts = list(train_forecasts_it)\n",
    "            train_labels = list(train_labels_it)\n",
    "\n",
    "            test_forecasts_it, test_labels_it = make_evaluation_predictions(\n",
    "                dataset=dataset['test'],\n",
    "                predictor=predictor,\n",
    "            )\n",
    "            test_forecasts = list(test_forecasts_it)\n",
    "            test_labels = list(test_labels_it)\n",
    "\n",
    "            highlight_print(f\"Level {level_idx}: Saving predictions\")\n",
    "            with open(f\"{level_dir}/{estimator_name}_train_labels.pkl\", \"wb\") as f:\n",
    "                pickle.dump(train_labels, f)\n",
    "            with open(f\"{level_dir}/{estimator_name}_train_forecasts.pkl\", \"wb\") as f:\n",
    "                pickle.dump(train_forecasts, f)\n",
    "            with open(f\"{level_dir}/{estimator_name}_test_labels.pkl\", \"wb\") as f:\n",
    "                pickle.dump(test_labels, f)\n",
    "            with open(f\"{level_dir}/{estimator_name}_test_forecasts.pkl\", \"wb\") as f:\n",
    "                pickle.dump(test_forecasts, f)\n",
    "\n",
    "            highlight_print(f\"Level {level_idx}: Evaluating predictions\")\n",
    "            evaluator = Evaluator(quantiles=(0.5,), ignore_invalid_values=True)\n",
    "            train_metrics_all_id, train_metrics_per_id = evaluator(train_labels, train_forecasts)\n",
    "            test_metrics_all_id, test_metrics_per_id = evaluator(test_labels, test_forecasts)\n",
    "\n",
    "            highlight_print(f\"Level {level_idx}: Saving evaluations\")\n",
    "            with open(f\"{level_dir}/{estimator_name}_train_metrics_all_id.pkl\", \"wb\") as f:\n",
    "                pickle.dump(train_metrics_all_id, f)\n",
    "            with open(f\"{level_dir}/{estimator_name}_train_metrics_per_id.pkl\", \"wb\") as f:\n",
    "                pickle.dump(train_metrics_per_id, f)\n",
    "            with open(f\"{level_dir}/{estimator_name}_test_metrics_all_id.pkl\", \"wb\") as f:\n",
    "                pickle.dump(test_metrics_all_id, f)\n",
    "            with open(f\"{level_dir}/{estimator_name}_test_metrics_per_id.pkl\", \"wb\") as f:\n",
    "                pickle.dump(test_metrics_per_id, f)\n",
    "\n",
    "            # reduce memory\n",
    "            del dataset, predictor, train_forecasts, train_labels, test_forecasts, test_labels\n",
    "            gc.collect()\n",
    "\n",
    "train_models(epochs=300, learning_rate=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
